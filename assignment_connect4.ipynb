{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20FY9jL149NO"
      },
      "source": [
        "# Adversarial Search: Playing Connect 4\n",
        "\n",
        "Student Name: Miller Boyd\n",
        "\n",
        "I have used the following AI tools: none\n",
        "\n",
        "I understand that my submission needs to be my own work: MB\n",
        "\n",
        "## Instructions\n",
        "\n",
        "Total Points: Undegraduates 100, graduate students 110\n",
        "\n",
        "Complete this notebook and submit it. The notebook needs to be a complete project report with your implementation, documentation including a short discussion of how your implementation works and your design choices, and experimental results (e.g., tables and charts with simulation results) with a short discussion of what they mean. Use the provided notebook cells and insert additional code and markdown cells as needed.\n",
        "\n",
        "## Introduction\n",
        "\n",
        "You will implement different versions of agents that play Connect 4:\n",
        "\n",
        "> \"Connect 4 is a two-player connection board game, in which the players choose a color and then take turns dropping colored discs into a seven-column, six-row vertically suspended grid. The pieces fall straight down, occupying the lowest available space within the column. The objective of the game is to be the first to form a horizontal, vertical, or diagonal line of four of one's own discs.\" (see [Connect Four on Wikipedia](https://en.wikipedia.org/wiki/Connect_Four))\n",
        "\n",
        "Note that [Connect-4 has been solved](https://en.wikipedia.org/wiki/Connect_Four#Mathematical_solution)\n",
        "in 1988. A connect-4 solver with a discussion of how to solve different parts of the problem can be found here: https://connect4.gamesolver.org/en/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUiDYHZW49NQ"
      },
      "source": [
        "## Task 1: Defining the Search Problem [10 point]\n",
        "\n",
        "Define the components of the search problem:\n",
        "\n",
        "* Initial state\n",
        "* Actions\n",
        "* Transition model (result function)\n",
        "* Goal state (terminal state and utility)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "eS89iB2a49NS"
      },
      "outputs": [],
      "source": [
        "# Your code/answer goes here.\n",
        "# Your code/answer goes here.\n",
        "import numpy as np\n",
        "\n",
        "# sets initial board to empty\n",
        "def init_state (board=(6, 7)):\n",
        "    return np.full(board=board, fill_value=0)\n",
        "\n",
        "# possible action locations\n",
        "actions = {0,1,2,3,4,5,6}\n",
        "\n",
        "def transition_model (player, state, action):\n",
        "    col_seg = state[:, action]\n",
        "    spot = np.where(col_seg == 0)[0]\n",
        "\n",
        "    # if there is spaces in the column\n",
        "    if spot.size > 0:\n",
        "        row = spot[-1]\n",
        "        state[row,action]  = player\n",
        "        return state\n",
        "\n",
        "    return None\n",
        "\n",
        "# define if the user has made a goal\n",
        "# state is the current board\n",
        "def goal (player, state, move):    \n",
        "\n",
        "    # Draw, so neutral utility\n",
        "    if np.all(state != 0):\n",
        "        return 0 \n",
        "\n",
        "    x,y = move\n",
        "    x2,y2 = move\n",
        "\n",
        "    row_seg = state[x, max(0, y-3):min(len(state), y+4)]\n",
        "    col_seg = state[max(0, x-3):min(len(state[0]), x+4), y]\n",
        "    diag_down_seg = [state[x][y]]\n",
        "    diag_up_seg = [state[x][y]]\n",
        "\n",
        "    while x < len(state) and x2 >= 0 and y < len(state[0] and y2 >= 0):\n",
        "        # increment / decrement indexes\n",
        "        x += 1\n",
        "        y += 1\n",
        "        x2 -= 1\n",
        "        y2 -= 1\n",
        "\n",
        "        # getting upper left\n",
        "        # -x-y\n",
        "        if x2 >= 0 and y2 >=0:\n",
        "            diag_down_seg.insert(0, state[x][y])\n",
        "        \n",
        "        # getting lower right\n",
        "        # +x+y\n",
        "        if x < len(state) and y < len(state[0]):\n",
        "            diag_down_seg.append(state[x][y])\n",
        "\n",
        "        # getting lower left\n",
        "        # -x+y\n",
        "        if x2 >= 0 and y < len(state[0]):\n",
        "            diag_up_seg.insert(0, state[x][y])\n",
        "        \n",
        "        # getting upper right\n",
        "        # +x-y\n",
        "        if x < len(state) and y >= 0:\n",
        "            diag_up_seg.append(state[x][y])\n",
        "\n",
        "    winning_sequence = [player] * 4\n",
        "    # check row\n",
        "    if np.any(np.convolve((row_seg == player).astype(int), winning_sequence, mode='valid') == 4):\n",
        "        return player\n",
        "    # check col\n",
        "    elif np.any(np.convolve((col_seg == player).astype(int), winning_sequence, mode='valid') == 4):\n",
        "        return player\n",
        "    # check diagonal down\n",
        "    elif np.any(np.convolve((diag_down_seg == player).astype(int), winning_sequence, mode='valid') == 4):\n",
        "        return player\n",
        "    # check diagonal down\n",
        "    elif np.any(np.convolve((diag_up_seg == player).astype(int), winning_sequence, mode='valid') == 4):\n",
        "        return player\n",
        "\n",
        "    return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUvBr2M749NU"
      },
      "source": [
        "How big is the state space? Give an estimate and explain it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "7Aj9A8XO49NW"
      },
      "outputs": [],
      "source": [
        "# Your code/ answer goes here.\n",
        "positions = 6 * 7\n",
        "state_space = 3^positions\n",
        "\n",
        "# you have possible states per position, so we would have 3 possible states and 42 possible positions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RnSwTohD49NX"
      },
      "source": [
        "How big is the game tree that minimax search will go through? Give an estimate and explain it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "2dypgV6R49NY"
      },
      "outputs": [],
      "source": [
        "# Your code/ answer goes here.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNhyWZ8-49Na"
      },
      "source": [
        "## Task 2: Game Environment and Random Agent [25 point]\n",
        "\n",
        "Use a numpy character array as the board."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "CrgBXfW549Nb",
        "outputId": "14e9a796-4ee8-4f33-e1f8-b9a1c5c2e986"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "def empty_board(shape=(6, 7)):\n",
        "    return np.full(shape=shape, fill_value=0)\n",
        "\n",
        "print(empty_board())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kePUlD2E49Nd"
      },
      "source": [
        "The standard board is $6 \\times 7$ but you can use smaller boards to test your code. Instead of colors (red and yellow), I use 1 and -1 to represent the players. Make sure that your agent functions all have the from: `agent_type(board, player = 1)`, where board is the current board position (in the format above) and player is the player whose next move it is and who the agent should play (as 1 and -1)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "hs2pjY-Q49Ne",
        "outputId": "ec417a68-9d1c-4e3e-c71c-de08fdbc5189",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Visualization code by Randolph Rankin\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def visualize(board):\n",
        "    plt.axes()\n",
        "    rectangle=plt.Rectangle((-0.5,len(board)*-1+0.5),len(board[0]),len(board),fc='blue')\n",
        "    circles=[]\n",
        "    for i,row in enumerate(board):\n",
        "        for j,val in enumerate(row):\n",
        "            color='white' if val==0 else 'red' if val==1 else 'yellow'\n",
        "            circles.append(plt.Circle((j,i*-1),0.4,fc=color))\n",
        "\n",
        "    plt.gca().add_patch(rectangle)\n",
        "    for circle in circles:\n",
        "        plt.gca().add_patch(circle)\n",
        "\n",
        "    plt.axis('scaled')\n",
        "    plt.show()\n",
        "\n",
        "board = [[0, 0, 0, 0, 0, 0, 0],\n",
        "         [0, 0, 0, 0, 0, 0, 0],\n",
        "         [0, 0, 0, 0, 0, 0, 0],\n",
        "         [0, 0, 0, 1, 0, 0, 0],\n",
        "         [0, 0, 0, 1, 0, 0, 0],\n",
        "         [0,-1,-1, 1,-1, 0, 0]]\n",
        "visualize(board)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EiJwO-Gn49Nf",
        "tags": []
      },
      "source": [
        "Implement helper functions for:\n",
        "\n",
        "* A check for available actions in each state `actions(s)`.\n",
        "* The transition model `result(s, a)`.\n",
        "* Check for terminal states `terminal(s)`.\n",
        "* The utility function `utility(s)`.\n",
        "\n",
        "Make sure that all these functions work with boards of different sizes (number of columns and rows)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "Cdtc_Ca449Ng"
      },
      "outputs": [],
      "source": [
        "# Your code/ answer goes here.\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "class ConnectFourBase:\n",
        "\n",
        "    def __init__(self, mark, rows=6, columns=7, board=None):\n",
        "        self.rows = rows\n",
        "        self.columns = columns\n",
        "        if board is None:\n",
        "            self.board = np.zeros((rows, columns), dtype=int)\n",
        "        else:\n",
        "            self.board = board\n",
        "        self.current_player = mark\n",
        "\n",
        "    def create_random_board(self, rows=None, columns=None):\n",
        "        # Create an empty board\n",
        "        if rows == None: rows = self.rows\n",
        "        if columns == None: columns = self.columns\n",
        "        board = np.zeros((rows, columns), dtype=int)\n",
        "        player = 1\n",
        "\n",
        "        for col in range(columns):\n",
        "            # Determine a random number of pieces in this column\n",
        "            pieces_in_col = random.randint(0, rows)\n",
        "\n",
        "            for row in range(pieces_in_col):\n",
        "                # Add a piece to the board, ensuring it's either a 1 or -1\n",
        "                board[row, col] = player\n",
        "                player *= -1\n",
        "\n",
        "        # The board has been built bottom-up, but traditionally, we visualize Connect 4 boards top-down,\n",
        "        # so we need to flip it vertically.\n",
        "        self.board = np.flip(board, 0)\n",
        "\n",
        "    # will return a +1 if player 1 has played and player 2 has not, otherwise a zero if player 2 has played or no playe has\n",
        "    # assuming game has started when function is called\n",
        "    def get_player(self):\n",
        "        num_plays = np.count_nonzero(self.board)\n",
        "\n",
        "        # If the number of plays is even, it's player 1's turn (return 1). Otherwise, it's player 2's turn (return -1).\n",
        "        return 1 if num_plays % 2 == 0 else -1\n",
        "\n",
        "\n",
        "    # returns an array with every column with available moves\n",
        "    def actions(self):\n",
        "        return [col for col in range(len(self.board[0])) if 0 in self.board[:,col]]\n",
        "\n",
        "    # update the state with the action\n",
        "    def result (self, action):\n",
        "        state = self.board.copy()\n",
        "        col_seg = state[:, action]\n",
        "        spot = np.where(col_seg == 0)[0]\n",
        "\n",
        "        # if there is spaces in the column\n",
        "        if spot.size > 0:\n",
        "            row = spot[-1]\n",
        "            state[row,action]  = self.current_player\n",
        "            return state\n",
        "\n",
        "        return None\n",
        "\n",
        "    def check_board(self):\n",
        "        # Define the winning sequence for players\n",
        "        player_markers = [1, -1]\n",
        "\n",
        "        # Define directions to check: vertical, horizontal, diagonal down-right, diagonal up-right\n",
        "        directions = [(0, 1), (1, 0), (1, 1), (-1, 1)]\n",
        "\n",
        "        for player in player_markers:\n",
        "            for row in range(self.rows):\n",
        "                for col in range(self.columns):\n",
        "                    # Check all four directions from the current cell\n",
        "                    for dr, dc in directions:\n",
        "                        if self.check_direction(row, col, dr, dc, player):\n",
        "                            return player  # Current player wins\n",
        "\n",
        "        # Check for a full board without a winner (draw)\n",
        "        if np.all(self.board != 0):\n",
        "            return 0  # Draw\n",
        "\n",
        "        return 2  # No winner yet\n",
        "    \n",
        "    def check_direction(self, start_row, start_col, dr, dc, player):\n",
        "        # Check if a line of four of the player's pieces exists starting from (start_row, start_col) in direction (dr, dc)\n",
        "        for i in range(4):\n",
        "            row = start_row + i * dr\n",
        "            col = start_col + i * dc\n",
        "            if not (0 <= row < self.rows and 0 <= col < self.columns):  # Check bounds\n",
        "                return False\n",
        "            if self.board[row, col] != player:\n",
        "                return False\n",
        "        return True\n",
        "\n",
        "    def terminal(self):\n",
        "        # The game is over if someone has won or the board is full (a draw).\n",
        "        result = self.check_board()\n",
        "        if result != 2:  # 2 indicates the game is still going on\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "\n",
        "    def utility(self):\n",
        "        result = self.check_board()\n",
        "        if result == 1:  # Player 1 wins\n",
        "            return 1\n",
        "        elif result == -1:  # Player 2 wins\n",
        "            return -1\n",
        "        elif result == 0:  # Draw\n",
        "            return 0  # Draw is typically considered a neutral outcome\n",
        "        else:\n",
        "            raise ValueError(\"Utility called on non-terminal state\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUemi0AI49Nh"
      },
      "source": [
        "Implement an agent that plays randomly. Make sure the agent function receives as the percept the board and returns a valid action. Use an agent function definition with the following signature (arguments):\n",
        "\n",
        "`def random_player(board, player = 1): ...`\n",
        "\n",
        "The argument `player` is used for agents that do not store what color they are playing. The value passed on by the environment should be 1 ot -1 for player red and yellow, respectively.  See [Experiments section for tic-tac-toe](https://nbviewer.org/github/mhahsler/CS7320-AI/blob/master/Games/tictactoe_and_or_tree_search.ipynb#Experiments) for an example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "C9OLJGWA49Nh"
      },
      "outputs": [],
      "source": [
        "# Your code/ answer goes here.\n",
        "class RandomAgent:\n",
        "    def __init__(self, mark):\n",
        "        self.mark = mark\n",
        "\n",
        "    def choose_action(self, game):\n",
        "        possible_moves = game.actions()\n",
        "        if possible_moves:\n",
        "            return random.choice(possible_moves)\n",
        "        return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJRuvtJn49Ni"
      },
      "source": [
        "Let two random agents play against each other 1000 times. Look at the [Experiments section for tic-tac-toe](https://nbviewer.org/github/mhahsler/CS7320-AI/blob/master/Games/tictactoe_and_or_tree_search.ipynb#Experiments) to see how the environment uses the agent functions to play against each other.\n",
        "\n",
        "How often does each player win? Is the result expected?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "IpELcazk49Ni",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Game results after 1000 games: {'Player 1 Wins': 554, 'Player 2 Wins': 443, 'Draws': 3}\n"
          ]
        }
      ],
      "source": [
        "# Your code/ answer goes here.\n",
        "def simulate_games(agent1, agent2, num_games):\n",
        "    results = {'Player 1 Wins': 0, 'Player 2 Wins': 0, 'Draws': 0}\n",
        "    for _ in range(num_games):\n",
        "        # Initialize the game\n",
        "        game = ConnectFourBase(mark=1)  # Start with player 1\n",
        "\n",
        "        while not game.terminal():\n",
        "            current_agent = agent1 if game.get_player() == 1 else agent2\n",
        "            action = current_agent.choose_action(game)\n",
        "            game.board = game.result(action)  # Update the game state\n",
        "            game.current_player *= -1  # Switch player\n",
        "\n",
        "        result = game.utility()\n",
        "        if result == 1:\n",
        "            results['Player 1 Wins'] += 1\n",
        "        elif result == -1:\n",
        "            results['Player 2 Wins'] += 1\n",
        "        else:\n",
        "            results['Draws'] += 1\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "agent1 = RandomAgent(mark=1)\n",
        "agent2 = RandomAgent(mark=-1)\n",
        "num_games = 1000\n",
        "\n",
        "game_results = simulate_games(agent1, agent2, num_games)\n",
        "print(\"Game results after\", num_games, \"games:\", game_results)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91cASKJA49Ni"
      },
      "source": [
        "## Task 3: Minimax Search with Alpha-Beta Pruning\n",
        "\n",
        "### Implement the Search [20 points]\n",
        "\n",
        "Implement minimax search starting from a given board for specifying the player.\n",
        "You can use code from the [tic-tac-toe example](https://nbviewer.org/github/mhahsler/CS7320-AI/blob/master/Games/tictactoe_alpha_beta_tree_search.ipynb).\n",
        "\n",
        "__Important Notes:__\n",
        "* Make sure that all your agent functions have a signature consistent with the random agent above and that it [uses a class to store state information.](https://nbviewer.org/github/mhahsler/CS7320-AI/blob/master/HOWTOs/store_agent_state_information.ipynb)\n",
        "This is essential to be able play against agents from other students later.\n",
        "* The search space for a $6 \\times 7$ board is large. You can experiment with smaller boards (the smallest is $4 \\times 4$) and/or changing the winning rule to connect 3 instead of 4."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "3sYRAjv649Nj"
      },
      "outputs": [],
      "source": [
        "# Your code/ answer goes here.\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "class ConnectFourMMABP:\n",
        "\n",
        "    def __init__(self, mark, rows=6, columns=7, board=None):\n",
        "        self.rows = rows\n",
        "        self.columns = columns\n",
        "        if board is None:\n",
        "            self.board = np.zeros((rows, columns), dtype=int)\n",
        "        else:\n",
        "            self.board = np.array(board, dtype=int)\n",
        "        self.current_player = mark\n",
        "        self.last_move = []\n",
        "\n",
        "    def create_random_board(self, rows=None, columns=None):\n",
        "        # Create an empty board\n",
        "        if rows == None: rows = self.rows\n",
        "        if columns == None: columns = self.columns\n",
        "        board = np.zeros((rows, columns), dtype=int)\n",
        "        player = self.get_player()\n",
        "\n",
        "        for col in range(columns):\n",
        "            # Determine a random number of pieces in this column\n",
        "            pieces_in_col = random.randint(0, rows)\n",
        "\n",
        "            for row in range(pieces_in_col):\n",
        "                # Add a piece to the board, ensuring it's either a 1 or -1\n",
        "                board[row, col] = player\n",
        "                player = -player\n",
        "\n",
        "        # The board has been built bottom-up, but traditionally, we visualize Connect 4 boards top-down,\n",
        "        # so we need to flip it vertically.\n",
        "        self.board = np.flip(board, 0)\n",
        "\n",
        "    # will return a +1 if player 1 has played and player 2 has not, otherwise a zero if player 2 has played or no playe has\n",
        "    # assuming game has started when function is called\n",
        "    def get_player(self):\n",
        "        num_plays = np.count_nonzero(self.board)\n",
        "\n",
        "        # If the number of plays is even, it's player 1's turn (return 1). Otherwise, it's player 2's turn (return -1).\n",
        "        return 1 if num_plays % 2 == 0 else -1\n",
        "\n",
        "    def actions(self):\n",
        "        return [col for col in range(self.columns) if self.board[0, col] == 0]\n",
        "\n",
        "    def result(self, action):\n",
        "        new_state = self.board.copy()\n",
        "        for row in range(self.rows - 1, -1, -1):  # Start checking from bottom row\n",
        "            if new_state[row, action] == 0:\n",
        "                new_state[row, action] = self.current_player\n",
        "                break\n",
        "        return new_state\n",
        "\n",
        "    def undo(self):\n",
        "        if self.last_move:\n",
        "            last_col = self.last_move.pop()\n",
        "            for row in range(self.rows):\n",
        "                if self.board[row, last_col] != 0:\n",
        "                    self.board[row, last_col] = 0\n",
        "                    break\n",
        "        self.current_player *= -1  # Switch back the player\n",
        "\n",
        "    def terminal(self):\n",
        "        return self.check_board() != 2\n",
        "\n",
        "    def utility(self):\n",
        "        result = self.check_board()\n",
        "        if result == 1:\n",
        "            return 1  # Maximizer wins\n",
        "        elif result == -1:\n",
        "            return -1  # Minimizer wins\n",
        "        return 0  # Draw\n",
        "\n",
        "    def check_direction(self, start_row, start_col, dr, dc, player):\n",
        "        # Check if a line of four of the player's pieces exists starting from (start_row, start_col) in direction (dr, dc)\n",
        "        for i in range(4):\n",
        "            row = start_row + i * dr\n",
        "            col = start_col + i * dc\n",
        "            if not (0 <= row < self.rows and 0 <= col < self.columns):  # Check bounds\n",
        "                return False\n",
        "            if self.board[row, col] != player:\n",
        "                return False\n",
        "        return True\n",
        "\n",
        "    def check_board(self):\n",
        "        # Define the winning sequence for players\n",
        "        player_markers = [1, -1]\n",
        "\n",
        "        # Define directions to check: vertical, horizontal, diagonal down-right, diagonal up-right\n",
        "        directions = [(0, 1), (1, 0), (1, 1), (-1, 1)]\n",
        "\n",
        "        for player in player_markers:\n",
        "            for row in range(self.rows):\n",
        "                for col in range(self.columns):\n",
        "                    # Check all four directions from the current cell\n",
        "                    for dr, dc in directions:\n",
        "                        if self.check_direction(row, col, dr, dc, player):\n",
        "                            return player  # Current player wins\n",
        "\n",
        "        # Check for a full board without a winner (draw)\n",
        "        if np.all(self.board != 0):\n",
        "            return 0  # Draw\n",
        "\n",
        "        return 2  # No winner yet\n",
        "\n",
        "    def minimax_search(self, depth=7, alpha=-math.inf, beta=math.inf):\n",
        "        # Perform a Minimax search with alpha-beta pruning\n",
        "        best_score, best_move = self.max_value(depth, alpha, beta)\n",
        "        return best_move, best_score\n",
        "\n",
        "    def max_value(self, depth, alpha, beta):\n",
        "        if depth == 0 or self.terminal():\n",
        "            return self.utility(), None\n",
        "        max_score, best_action = -math.inf, None\n",
        "        for action in self.actions():\n",
        "            new_state = self.result(action)\n",
        "            self.board = new_state\n",
        "            self.current_player = -self.current_player\n",
        "            score, _ = self.min_value(depth - 1, alpha, beta)\n",
        "            self.board = self.board  # Reset to the original state\n",
        "            self.current_player = -self.current_player\n",
        "            if score > max_score:\n",
        "                max_score, best_action = score, action\n",
        "            alpha = max(alpha, score)\n",
        "            if alpha >= beta:\n",
        "                break\n",
        "        return max_score, best_action\n",
        "\n",
        "    def min_value(self, depth, alpha, beta):\n",
        "        if depth == 0 or self.terminal():\n",
        "            return self.utility(), None\n",
        "        min_score, best_action = math.inf, None\n",
        "        for action in self.actions():\n",
        "            new_state = self.result(action)\n",
        "            self.board = new_state\n",
        "            self.current_player = -self.current_player\n",
        "            score, _ = self.max_value(depth - 1, alpha, beta)\n",
        "            self.board = self.board  # Reset to the original state\n",
        "            self.current_player = -self.current_player\n",
        "            if score < min_score:\n",
        "                min_score, best_action = score, action\n",
        "            beta = min(beta, score)\n",
        "            if beta <= alpha:\n",
        "                break\n",
        "        return min_score, best_action\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8lfJEc149Nk"
      },
      "source": [
        "Experiment with some manually created boards (at least 5) to check if the agent spots winning opportunities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "Nm-tshCF49Nk"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Board 1:\n",
            "[[ 0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0]\n",
            " [ 0  0  0  1 -1  0  0]\n",
            " [ 0  0  1 -1  1  0  0]]\n",
            "Move: 0, Score: 1\n",
            "\n",
            "Board 2:\n",
            "[[ 0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0]\n",
            " [ 0  0  0 -1  1  0  0]\n",
            " [ 0  0  0  1 -1  0  0]\n",
            " [ 0  0  0 -1  1  0  0]\n",
            " [ 0  0  1  1 -1  0  0]]\n",
            "Move: 0, Score: 1\n",
            "\n",
            "Board 3:\n",
            "[[ 0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0]\n",
            " [ 0  0  0 -1  1  0  0]\n",
            " [ 0  0  0  1 -1  0  0]\n",
            " [ 0  0  0  1  1 -1  0]]\n",
            "Move: 0, Score: 1\n",
            "\n",
            "Board 4:\n",
            "[[ 0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0]\n",
            " [ 0  0  0  1  0  0  0]\n",
            " [ 0  0  0  1 -1  0  0]\n",
            " [ 0  0  0  1  1  1  0]]\n",
            "Move: 0, Score: 1\n",
            "\n",
            "Board 5:\n",
            "[[ 0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0]\n",
            " [ 1  1  1 -1 -1 -1  1]]\n",
            "Move: 0, Score: 1\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define five predefined boards\n",
        "boards = [\n",
        "    np.array([\n",
        "        [0, 0, 0, 0, 0, 0, 0],\n",
        "        [0, 0, 0, 0, 0, 0, 0],\n",
        "        [0, 0, 0, 0, 0, 0, 0],\n",
        "        [0, 0, 0, 0, 0, 0, 0],\n",
        "        [0, 0, 0, 1, -1, 0, 0],\n",
        "        [0, 0, 1, -1, 1, 0, 0]\n",
        "    ]),\n",
        "    np.array([\n",
        "        [0, 0, 0, 0, 0, 0, 0],\n",
        "        [0, 0, 0, 0, 0, 0, 0],\n",
        "        [0, 0, 0, -1, 1, 0, 0],\n",
        "        [0, 0, 0, 1, -1, 0, 0],\n",
        "        [0, 0, 0, -1, 1, 0, 0],\n",
        "        [0, 0, 1, 1, -1, 0, 0]\n",
        "    ]),\n",
        "    np.array([\n",
        "        [0, 0, 0, 0, 0, 0, 0],\n",
        "        [0, 0, 0, 0, 0, 0, 0],\n",
        "        [0, 0, 0, 0, 0, 0, 0],\n",
        "        [0, 0, 0, -1, 1, 0, 0],\n",
        "        [0, 0, 0, 1, -1, 0, 0],\n",
        "        [0, 0, 0, 1, 1, -1, 0]\n",
        "    ]),\n",
        "    np.array([\n",
        "        [0, 0, 0, 0, 0, 0, 0],\n",
        "        [0, 0, 0, 0, 0, 0, 0],\n",
        "        [0, 0, 0, 0, 0, 0, 0],\n",
        "        [0, 0, 0, 1, 0, 0, 0],\n",
        "        [0, 0, 0, 1, -1, 0, 0],\n",
        "        [0, 0, 0, 1, 1, 1, 0]\n",
        "    ]),\n",
        "    np.array([\n",
        "        [0, 0, 0, 0, 0, 0, 0],\n",
        "        [0, 0, 0, 0, 0, 0, 0],\n",
        "        [0, 0, 0, 0, 0, 0, 0],\n",
        "        [0, 0, 0, 0, 0, 0, 0],\n",
        "        [0, 0, 0, 0, 0, 0, 0],\n",
        "        [1, 1, 1, -1, -1, -1, 1]\n",
        "    ])\n",
        "]\n",
        "\n",
        "# Test the ConnectFourMMABP agent with these boards\n",
        "for i, board in enumerate(boards):\n",
        "    game = ConnectFourMMABP(mark=1, board=board)\n",
        "    print(f\"Board {i+1}:\")\n",
        "    print(game.board)\n",
        "    move, score = game.minimax_search()\n",
        "    print(f\"Move: {move}, Score: {score}\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTH4xXWV49Nk"
      },
      "source": [
        "How long does it take to make a move? Start with a smaller board with 4 columns and make the board larger by adding columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "c0rlxeKF49Nl"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Columns: 4, Time Taken: 0.0010 seconds, Score: 1, Move: 0\n",
            "Columns: 5, Time Taken: 0.0016 seconds, Score: 1, Move: 0\n",
            "Columns: 6, Time Taken: 0.0010 seconds, Score: 1, Move: 0\n",
            "Columns: 7, Time Taken: 0.0020 seconds, Score: 1, Move: 0\n",
            "Columns: 8, Time Taken: 0.0030 seconds, Score: 1, Move: 0\n",
            "Columns: 9, Time Taken: 0.0035 seconds, Score: 1, Move: 0\n",
            "Columns: 10, Time Taken: 0.0030 seconds, Score: 1, Move: 0\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[(4, 0.0010061264038085938, 1, 0),\n",
              " (5, 0.0015959739685058594, 1, 0),\n",
              " (6, 0.0010247230529785156, 1, 0),\n",
              " (7, 0.002000093460083008, 1, 0),\n",
              " (8, 0.0030007362365722656, 1, 0),\n",
              " (9, 0.0034966468811035156, 1, 0),\n",
              " (10, 0.003000974655151367, 1, 0)]"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Your code/ answer goes here.\n",
        "import time\n",
        "\n",
        "def test_minimax_timing(printy):\n",
        "    results = []\n",
        "    for columns in range(4, 11):  # Testing boards from 4 to 10 columns\n",
        "        game = ConnectFourMMABP(mark=1, rows=6, columns=columns)\n",
        "        start_time = time.time()\n",
        "        move, score = game.minimax_search()\n",
        "        duration = time.time() - start_time\n",
        "        results.append((columns, duration, score, move))\n",
        "        if printy == 1: print(f\"Columns: {columns}, Time Taken: {duration:.4f} seconds, Score: {score}, Move: {move}\")\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "test_minimax_timing(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3ofmxJd49Nm"
      },
      "source": [
        "### Move ordering [5 points]\n",
        "\n",
        "Starting the search with better moves will increase the efficiency of alpha-beta pruning. Describe and implement a simple move ordering strategy. Make a table that shows how the ordering strategies influence the time it takes to make a move?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "Q2LdkDPT49Nn"
      },
      "outputs": [],
      "source": [
        "# Your code/ answer goes here.\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "class ConnectFourMMABP_MO:\n",
        "\n",
        "    def __init__(self, mark, rows=6, columns=7, board=None):\n",
        "        self.rows = rows\n",
        "        self.columns = columns\n",
        "        if board is None:\n",
        "            self.board = np.zeros((rows, columns), dtype=int)\n",
        "        else:\n",
        "            self.board = np.array(board, dtype=int)\n",
        "        self.current_player = mark\n",
        "        self.last_move = []\n",
        "\n",
        "    def create_random_board(self, rows=None, columns=None):\n",
        "        # Create an empty board\n",
        "        if rows == None: rows = self.rows\n",
        "        if columns == None: columns = self.columns\n",
        "        board = np.zeros((rows, columns), dtype=int)\n",
        "        player = self.get_player()\n",
        "\n",
        "        for col in range(columns):\n",
        "            # Determine a random number of pieces in this column\n",
        "            pieces_in_col = random.randint(0, rows)\n",
        "\n",
        "            for row in range(pieces_in_col):\n",
        "                # Add a piece to the board, ensuring it's either a 1 or -1\n",
        "                board[row, col] = player\n",
        "                player = -player\n",
        "\n",
        "        # The board has been built bottom-up, but traditionally, we visualize Connect 4 boards top-down,\n",
        "        # so we need to flip it vertically.\n",
        "        self.board = np.flip(board, 0)\n",
        "\n",
        "    # will return a +1 if player 1 has played and player 2 has not, otherwise a zero if player 2 has played or no playe has\n",
        "    # assuming game has started when function is called\n",
        "    def get_player(self):\n",
        "        num_plays = np.count_nonzero(self.board)\n",
        "\n",
        "        # If the number of plays is even, it's player 1's turn (return 1). Otherwise, it's player 2's turn (return -1).\n",
        "        return 1 if num_plays % 2 == 0 else -1\n",
        "\n",
        "    def actions(self):\n",
        "        center = self.columns // 2\n",
        "        # Order actions based on their distance from the center column\n",
        "        return sorted([col for col in range(self.columns) if self.board[0, col] == 0],\n",
        "                    key=lambda x: abs(x - center))\n",
        "\n",
        "\n",
        "    def result(self, action):\n",
        "        new_state = self.board.copy()\n",
        "        for row in range(self.rows - 1, -1, -1):  # Start checking from bottom row\n",
        "            if new_state[row, action] == 0:\n",
        "                new_state[row, action] = self.current_player\n",
        "                break\n",
        "        return new_state\n",
        "\n",
        "    def undo(self):\n",
        "        if self.last_move:\n",
        "            last_col = self.last_move.pop()\n",
        "            for row in range(self.rows):\n",
        "                if self.board[row, last_col] != 0:\n",
        "                    self.board[row, last_col] = 0\n",
        "                    break\n",
        "        self.current_player *= -1  # Switch back the player\n",
        "\n",
        "    def terminal(self):\n",
        "        return self.check_board() != 2\n",
        "\n",
        "    def utility(self):\n",
        "        result = self.check_board()\n",
        "        if result == 1:\n",
        "            return 1  # Maximizer wins\n",
        "        elif result == -1:\n",
        "            return -1  # Minimizer wins\n",
        "        return 0  # Draw\n",
        "\n",
        "    def evaluate_segment(self, segment, player):\n",
        "        score = 0\n",
        "        opponent = -player\n",
        "        player_count = np.count_nonzero(segment == player)\n",
        "        opponent_count = np.count_nonzero(segment == opponent)\n",
        "        empty_count = np.count_nonzero(segment == 0)\n",
        "\n",
        "        # More nuanced scoring\n",
        "        if player_count == 4:\n",
        "            score += 10000  # Winning condition\n",
        "        elif opponent_count == 4:\n",
        "            score -= 5000   # Losing condition\n",
        "        elif player_count == 3 and empty_count == 1:\n",
        "            score += 100    # Potential to win\n",
        "        elif opponent_count == 3 and empty_count == 1:\n",
        "            score -= 50     # Need to block opponent\n",
        "        elif player_count == 2 and empty_count == 2:\n",
        "            score += 10     # Building opportunity\n",
        "        elif opponent_count == 2 and empty_count == 2:\n",
        "            score -= 5      # Opponent building opportunity\n",
        "\n",
        "        return score\n",
        "\n",
        "    def heuristic(self):\n",
        "        score = 0\n",
        "        player = self.current_player\n",
        "\n",
        "        for row in range(self.rows):\n",
        "            for col in range(self.columns - 3):\n",
        "                # Evaluate horizontal segment\n",
        "                horiz_seg = self.board[row, col:col+4]\n",
        "                score += self.evaluate_segment(horiz_seg, player)\n",
        "\n",
        "                if row < self.rows - 3:\n",
        "                    # Evaluate vertical segment\n",
        "                    vert_seg = self.board[row:row+4, col]\n",
        "                    score += self.evaluate_segment(vert_seg, player)\n",
        "\n",
        "                    # Evaluate diagonal segments\n",
        "                    diag1 = self.board[row:row+4, col:col+4].diagonal()\n",
        "                    score += self.evaluate_segment(diag1, player)\n",
        "                    diag2 = np.fliplr(self.board[row:row+4, col:col+4]).diagonal()\n",
        "                    score += self.evaluate_segment(diag2, player)\n",
        "\n",
        "        # Consider center column control as a strategy\n",
        "        center_col = self.columns // 2\n",
        "        center_control = np.count_nonzero(self.board[:, center_col] == player)\n",
        "        score += center_control * 3  # Additional points for center control\n",
        "\n",
        "        return score\n",
        "\n",
        "\n",
        "    def check_direction(self, start_row, start_col, dr, dc, player):\n",
        "        # Check if a line of four of the player's pieces exists starting from (start_row, start_col) in direction (dr, dc)\n",
        "        for i in range(4):\n",
        "            row = start_row + i * dr\n",
        "            col = start_col + i * dc\n",
        "            if not (0 <= row < self.rows and 0 <= col < self.columns):  # Check bounds\n",
        "                return False\n",
        "            if self.board[row, col] != player:\n",
        "                return False\n",
        "        return True\n",
        "\n",
        "    def check_board(self):\n",
        "        # Define the winning sequence for players\n",
        "        player_markers = [1, -1]\n",
        "\n",
        "        # Define directions to check: vertical, horizontal, diagonal down-right, diagonal up-right\n",
        "        directions = [(0, 1), (1, 0), (1, 1), (-1, 1)]\n",
        "\n",
        "        for player in player_markers:\n",
        "            for row in range(self.rows):\n",
        "                for col in range(self.columns):\n",
        "                    # Check all four directions from the current cell\n",
        "                    for dr, dc in directions:\n",
        "                        if self.check_direction(row, col, dr, dc, player):\n",
        "                            return player  # Current player wins\n",
        "\n",
        "        # Check for a full board without a winner (draw)\n",
        "        if np.all(self.board != 0):\n",
        "            return 0  # Draw\n",
        "\n",
        "        return 2  # No winner yet\n",
        "\n",
        "    def minimax_search(self, depth=7, alpha=-math.inf, beta=math.inf):\n",
        "        # Perform a Minimax search with alpha-beta pruning\n",
        "        best_score, best_move = self.max_value(depth, alpha, beta)\n",
        "        return best_move, best_score\n",
        "\n",
        "    def max_value(self, depth, alpha, beta):\n",
        "        if depth == 0 or self.terminal():\n",
        "            return self.utility(), None\n",
        "        max_score, best_action = -math.inf, None\n",
        "        for action in self.actions():\n",
        "            new_state = self.result(action)\n",
        "            self.board = new_state\n",
        "            self.current_player = -self.current_player\n",
        "            score, _ = self.min_value(depth - 1, alpha, beta)\n",
        "            self.board = self.board  # Reset to the original state\n",
        "            self.current_player = -self.current_player\n",
        "            if score > max_score:\n",
        "                max_score, best_action = score, action\n",
        "            alpha = max(alpha, score)\n",
        "            if alpha >= beta:\n",
        "                break\n",
        "        return max_score, best_action\n",
        "\n",
        "    def min_value(self, depth, alpha, beta):\n",
        "        if depth == 0 or self.terminal():\n",
        "            return self.utility(), None\n",
        "        min_score, best_action = math.inf, None\n",
        "        for action in self.actions():\n",
        "            new_state = self.result(action)\n",
        "            self.board = new_state\n",
        "            self.current_player = -self.current_player\n",
        "            score, _ = self.max_value(depth - 1, alpha, beta)\n",
        "            self.board = self.board  # Reset to the original state\n",
        "            self.current_player = -self.current_player\n",
        "            if score < min_score:\n",
        "                min_score, best_action = score, action\n",
        "            beta = min(beta, score)\n",
        "            if beta <= alpha:\n",
        "                break\n",
        "        return min_score, best_action\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Columns: 4, Time Taken: 0.0005 seconds, Score: 1, Move: 2\n",
            "Columns: 5, Time Taken: 0.0025 seconds, Score: 1, Move: 2\n",
            "Columns: 6, Time Taken: 0.0020 seconds, Score: 1, Move: 3\n",
            "Columns: 7, Time Taken: 0.0020 seconds, Score: 1, Move: 3\n",
            "Columns: 8, Time Taken: 0.0024 seconds, Score: 1, Move: 4\n",
            "Columns: 9, Time Taken: 0.0035 seconds, Score: 1, Move: 4\n",
            "Columns: 10, Time Taken: 0.0037 seconds, Score: 1, Move: 5\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[(4, 0.0005388259887695312, 1, 2),\n",
              " (5, 0.002513408660888672, 1, 2),\n",
              " (6, 0.0019996166229248047, 1, 3),\n",
              " (7, 0.0019958019256591797, 1, 3),\n",
              " (8, 0.002363443374633789, 1, 4),\n",
              " (9, 0.003503084182739258, 1, 4),\n",
              " (10, 0.0037326812744140625, 1, 5)]"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Your code/ answer goes here.\n",
        "import time\n",
        "\n",
        "def test_minimax_order_timing(printy):\n",
        "    results = []\n",
        "    for columns in range(4, 11):  # Testing boards from 4 to 10 columns\n",
        "        game = ConnectFourMMABP_MO(mark=1, rows=6, columns=columns)\n",
        "        start_time = time.time()\n",
        "        move, score = game.minimax_search()\n",
        "        duration = time.time() - start_time\n",
        "        results.append((columns, duration, score, move))\n",
        "        if printy == 1: print(f\"Columns: {columns}, Time Taken: {duration:.4f} seconds, Score: {score}, Move: {move}\")\n",
        "\n",
        "    return results\n",
        "\n",
        "test_minimax_order_timing(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[(4, 0.0019261837005615234, 1, 0), (5, 0.002003908157348633, 1, 0), (6, 0.0009999275207519531, 1, 0), (7, 0.002000570297241211, 1, 0), (8, 0.0030095577239990234, 1, 0), (9, 0.0036118030548095703, 1, 0), (10, 0.00404667854309082, 1, 0)]\n",
            "[(4, 0.000997781753540039, 1, 2), (5, 0.0009975433349609375, 1, 2), (6, 0.002025127410888672, 1, 3), (7, 0.002293109893798828, 1, 3), (8, 0.002002716064453125, 1, 4), (9, 0.004036903381347656, 1, 4), (10, 0.003514528274536133, 1, 5)]\n",
            "   Columns  Time Taken (r1)  Score (r1)  Move (r1)  Time Taken (r2)  \\\n",
            "0        4         0.001926           1          0         0.000998   \n",
            "1        5         0.002004           1          0         0.000998   \n",
            "2        6         0.001000           1          0         0.002025   \n",
            "3        7         0.002001           1          0         0.002293   \n",
            "4        8         0.003010           1          0         0.002003   \n",
            "5        9         0.003612           1          0         0.004037   \n",
            "6       10         0.004047           1          0         0.003515   \n",
            "\n",
            "   Score (r2)  Move (r2)  \n",
            "0           1          2  \n",
            "1           1          2  \n",
            "2           1          3  \n",
            "3           1          3  \n",
            "4           1          4  \n",
            "5           1          4  \n",
            "6           1          5  \n"
          ]
        }
      ],
      "source": [
        "r1 = test_minimax_timing(0)\n",
        "r2 = test_minimax_order_timing(0)\n",
        "\n",
        "print(r1)\n",
        "print(r2)\n",
        "\n",
        "# Create DataFrames\n",
        "df1 = pd.DataFrame(r1, columns=['Columns', 'Time Taken (r1)', 'Score (r1)', 'Move (r1)'])\n",
        "df2 = pd.DataFrame(r2, columns=['Columns', 'Time Taken (r2)', 'Score (r2)', 'Move (r2)'])\n",
        "\n",
        "# Merge DataFrames on 'Columns'\n",
        "comparison_df = pd.merge(df1, df2, on='Columns')\n",
        "\n",
        "# Display the DataFrame\n",
        "print(comparison_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huDaPgxy49No"
      },
      "source": [
        "### The first few moves [5 points]\n",
        "\n",
        "Start with an empty board. This is the worst case scenario for minimax search since it needs solve all possible games that can be played (minus some pruning) before making the decision. What can you do?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eREgCZHw49Np"
      },
      "outputs": [],
      "source": [
        "# Your code/ answer goes here.\n",
        "Starting with an empty board really puts the minimax algorithm to the test because it has to consider almost every possible game outcome before making a move. Heres what I would do to handle this complexity:\n",
        "\n",
        "    Depth-Limiting: I limit the search to a few moves ahead instead of trying to reach the end of the game. This reduces the number of scenarios the algorithm needs to evaluate.\n",
        "\n",
        "    Move Ordering: I prioritize more promising moves, like starting from the center in Connect Four, which can lead to better performance with alpha-beta pruning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8Aj6iGv49Nq"
      },
      "source": [
        "### Playtime [5 points]\n",
        "\n",
        "Let the Minimax Search agent play a random agent on a small board. Analyze wins, losses and draws."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "1SLWe4ik49Nq"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Game results after 1000 games: {'Player 1 Wins': 1000, 'Player 2 Wins': 0, 'Draws': 0}\n"
          ]
        }
      ],
      "source": [
        "# Your code/ answer goes here.\n",
        "class MinimaxAgent:\n",
        "    def __init__(self, mark):\n",
        "        self.mark = mark\n",
        "\n",
        "    def choose_action(self, game):\n",
        "        best_move, best_score = game.minimax_search()\n",
        "        return best_move\n",
        "\n",
        "def simulate_games(agent1, agent2, num_games):\n",
        "    results = {'Player 1 Wins': 0, 'Player 2 Wins': 0, 'Draws': 0}\n",
        "    for _ in range(num_games):\n",
        "        game = ConnectFourMMABP_MO(mark=1)\n",
        "        while not game.terminal():\n",
        "            current_agent = agent1 if game.current_player == 1 else agent2\n",
        "            action = current_agent.choose_action(game)\n",
        "            if action is not None:\n",
        "                game.board = game.result(action)\n",
        "                game.current_player *= -1  # Switch player\n",
        "            else:\n",
        "                break\n",
        "\n",
        "        result = game.utility()\n",
        "        if result == 1:\n",
        "            results['Player 1 Wins'] += 1\n",
        "        elif result == -1:\n",
        "            results['Player 2 Wins'] += 1\n",
        "        else:\n",
        "            results['Draws'] += 1\n",
        "\n",
        "    return results\n",
        "\n",
        "# Initialize agents\n",
        "minimax_agent = MinimaxAgent(mark=1)\n",
        "random_agent = RandomAgent(mark=-1)\n",
        "num_games = 1000\n",
        "\n",
        "# Run simulation\n",
        "game_results = simulate_games(minimax_agent, random_agent, num_games)\n",
        "print(\"Game results after\", num_games, \"games:\", game_results)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZl0HzO849Nq"
      },
      "source": [
        "## Task 4: Heuristic Alpha-Beta Tree Search\n",
        "\n",
        "### Heuristic evaluation function [15 points]\n",
        "\n",
        "Define and implement a heuristic evaluation function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "4nnFfokQ49Nr"
      },
      "outputs": [],
      "source": [
        "# Your code/ answer goes here.\n",
        "# Your code/ answer goes here.\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "class ConnectFourHueristic:\n",
        "\n",
        "    def __init__(self, mark, rows=6, columns=7, board=None):\n",
        "        self.rows = rows\n",
        "        self.columns = columns\n",
        "        if board is None:\n",
        "            self.board = np.zeros((rows, columns), dtype=int)\n",
        "        else:\n",
        "            self.board = np.array(board, dtype=int)\n",
        "        self.current_player = mark\n",
        "        self.last_move = []\n",
        "\n",
        "    def create_random_board(self, rows=None, columns=None):\n",
        "        # Create an empty board\n",
        "        if rows == None: rows = self.rows\n",
        "        if columns == None: columns = self.columns\n",
        "        board = np.zeros((rows, columns), dtype=int)\n",
        "        player = self.get_player()\n",
        "\n",
        "        for col in range(columns):\n",
        "            # Determine a random number of pieces in this column\n",
        "            pieces_in_col = random.randint(0, rows)\n",
        "\n",
        "            for row in range(pieces_in_col):\n",
        "                # Add a piece to the board, ensuring it's either a 1 or -1\n",
        "                board[row, col] = player\n",
        "                player = -player\n",
        "\n",
        "        # The board has been built bottom-up, but traditionally, we visualize Connect 4 boards top-down,\n",
        "        # so we need to flip it vertically.\n",
        "        self.board = np.flip(board, 0)\n",
        "\n",
        "    # will return a +1 if player 1 has played and player 2 has not, otherwise a zero if player 2 has played or no playe has\n",
        "    # assuming game has started when function is called\n",
        "    def get_player(self):\n",
        "        num_plays = np.count_nonzero(self.board)\n",
        "\n",
        "        # If the number of plays is even, it's player 1's turn (return 1). Otherwise, it's player 2's turn (return -1).\n",
        "        return 1 if num_plays % 2 == 0 else -1\n",
        "\n",
        "    def actions(self):\n",
        "        center = self.columns // 2\n",
        "        # Order actions based on their distance from the center column\n",
        "        return sorted([col for col in range(self.columns) if self.board[0, col] == 0],\n",
        "                    key=lambda x: abs(x - center))\n",
        "\n",
        "\n",
        "    def result(self, action):\n",
        "        new_state = self.board.copy()\n",
        "        for row in range(self.rows - 1, -1, -1):  # Start checking from bottom row\n",
        "            if new_state[row, action] == 0:\n",
        "                new_state[row, action] = self.current_player\n",
        "                break\n",
        "        return new_state\n",
        "\n",
        "    def undo(self):\n",
        "        if self.last_move:\n",
        "            last_col = self.last_move.pop()\n",
        "            for row in range(self.rows):\n",
        "                if self.board[row, last_col] != 0:\n",
        "                    self.board[row, last_col] = 0\n",
        "                    break\n",
        "        self.current_player *= -1  # Switch back the player\n",
        "\n",
        "    def terminal(self):\n",
        "        return self.check_board() != 2\n",
        "\n",
        "    def utility(self):\n",
        "        result = self.check_board()\n",
        "        if result == 1:\n",
        "            return 1  # Maximizer wins\n",
        "        elif result == -1:\n",
        "            return -1  # Minimizer wins\n",
        "        return 0  # Draw\n",
        "\n",
        "    def evaluate_segment(self, segment, player):\n",
        "        score = 0\n",
        "        opponent = -player\n",
        "        player_count = np.count_nonzero(segment == player)\n",
        "        opponent_count = np.count_nonzero(segment == opponent)\n",
        "        empty_count = np.count_nonzero(segment == 0)\n",
        "\n",
        "        # More nuanced scoring\n",
        "        if player_count == 4:\n",
        "            score += 10000  # Winning condition\n",
        "        elif opponent_count == 4:\n",
        "            score -= 5000   # Losing condition\n",
        "        elif player_count == 3 and empty_count == 1:\n",
        "            score += 100    # Potential to win\n",
        "        elif opponent_count == 3 and empty_count == 1:\n",
        "            score -= 50     # Need to block opponent\n",
        "        elif player_count == 2 and empty_count == 2:\n",
        "            score += 10     # Building opportunity\n",
        "        elif opponent_count == 2 and empty_count == 2:\n",
        "            score -= 5      # Opponent building opportunity\n",
        "\n",
        "        return score\n",
        "\n",
        "    def heuristic(self):\n",
        "        score = 0\n",
        "        player = self.current_player\n",
        "\n",
        "        for row in range(self.rows):\n",
        "            for col in range(self.columns - 3):\n",
        "                # Evaluate horizontal segment\n",
        "                horiz_seg = self.board[row, col:col+4]\n",
        "                score += self.evaluate_segment(horiz_seg, player)\n",
        "\n",
        "                if row < self.rows - 3:\n",
        "                    # Evaluate vertical segment\n",
        "                    vert_seg = self.board[row:row+4, col]\n",
        "                    score += self.evaluate_segment(vert_seg, player)\n",
        "\n",
        "                    # Evaluate diagonal segments\n",
        "                    diag1 = self.board[row:row+4, col:col+4].diagonal()\n",
        "                    score += self.evaluate_segment(diag1, player)\n",
        "                    diag2 = np.fliplr(self.board[row:row+4, col:col+4]).diagonal()\n",
        "                    score += self.evaluate_segment(diag2, player)\n",
        "\n",
        "        # Consider center column control as a strategy\n",
        "        center_col = self.columns // 2\n",
        "        center_control = np.count_nonzero(self.board[:, center_col] == player)\n",
        "        score += center_control * 3  # Additional points for center control\n",
        "\n",
        "        return score\n",
        "\n",
        "\n",
        "    def check_direction(self, start_row, start_col, dr, dc, player):\n",
        "        # Check if a line of four of the player's pieces exists starting from (start_row, start_col) in direction (dr, dc)\n",
        "        for i in range(4):\n",
        "            row = start_row + i * dr\n",
        "            col = start_col + i * dc\n",
        "            if not (0 <= row < self.rows and 0 <= col < self.columns):  # Check bounds\n",
        "                return False\n",
        "            if self.board[row, col] != player:\n",
        "                return False\n",
        "        return True\n",
        "\n",
        "    def check_board(self):\n",
        "        # Define the winning sequence for players\n",
        "        player_markers = [1, -1]\n",
        "\n",
        "        # Define directions to check: vertical, horizontal, diagonal down-right, diagonal up-right\n",
        "        directions = [(0, 1), (1, 0), (1, 1), (-1, 1)]\n",
        "\n",
        "        for player in player_markers:\n",
        "            for row in range(self.rows):\n",
        "                for col in range(self.columns):\n",
        "                    # Check all four directions from the current cell\n",
        "                    for dr, dc in directions:\n",
        "                        if self.check_direction(row, col, dr, dc, player):\n",
        "                            return player  # Current player wins\n",
        "\n",
        "        # Check for a full board without a winner (draw)\n",
        "        if np.all(self.board != 0):\n",
        "            return 0  # Draw\n",
        "\n",
        "        return 2  # No winner yet\n",
        "\n",
        "    def minimax_search(self, alpha=-math.inf, beta=math.inf):\n",
        "        # Perform a Minimax search with alpha-beta pruning\n",
        "        best_score, best_move = self.max_value(alpha, beta)\n",
        "        return best_move, best_score\n",
        "\n",
        "    def max_value(self, alpha, beta):\n",
        "        if self.terminal():\n",
        "            return self.heuristic(), None\n",
        "        max_score, best_action = -math.inf, None\n",
        "        for action in self.actions():\n",
        "            new_state = self.result(action)\n",
        "            self.board = new_state\n",
        "            self.current_player = -self.current_player\n",
        "            score, _ = self.min_value(alpha, beta)\n",
        "            self.board = self.board  # Reset to the original state\n",
        "            self.current_player = -self.current_player\n",
        "            if score > max_score:\n",
        "                max_score, best_action = score, action\n",
        "            alpha = max(alpha, score)\n",
        "            if alpha >= beta:\n",
        "                break\n",
        "        return max_score, best_action\n",
        "\n",
        "    def min_value(self, alpha, beta):\n",
        "        if self.terminal():\n",
        "            return self.heuristic(), None\n",
        "        min_score, best_action = math.inf, None\n",
        "        for action in self.actions():\n",
        "            new_state = self.result(action)\n",
        "            self.board = new_state\n",
        "            self.current_player = -self.current_player\n",
        "            score, _ = self.max_value(alpha, beta)\n",
        "            self.board = self.board  # Reset to the original state\n",
        "            self.current_player = -self.current_player\n",
        "            if score < min_score:\n",
        "                min_score, best_action = score, action\n",
        "            beta = min(beta, score)\n",
        "            if beta <= alpha:\n",
        "                break\n",
        "        return min_score, best_action\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Columns: 4, Time Taken: 0.0030 seconds, Score: 15009, Move: 2\n",
            "Columns: 5, Time Taken: 0.0065 seconds, Score: 30009, Move: 2\n",
            "Columns: 6, Time Taken: 0.0115 seconds, Score: 45009, Move: 3\n",
            "Columns: 7, Time Taken: 0.0185 seconds, Score: 60009, Move: 3\n",
            "Columns: 8, Time Taken: 0.0260 seconds, Score: 75009, Move: 4\n",
            "Columns: 9, Time Taken: 0.0375 seconds, Score: 90009, Move: 4\n",
            "Columns: 10, Time Taken: 0.0499 seconds, Score: 105009, Move: 5\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[(4, 0.0030002593994140625, 15009, 2),\n",
              " (5, 0.006501674652099609, 30009, 2),\n",
              " (6, 0.01150202751159668, 45009, 3),\n",
              " (7, 0.01850605010986328, 60009, 3),\n",
              " (8, 0.025997638702392578, 75009, 4),\n",
              " (9, 0.037532806396484375, 90009, 4),\n",
              " (10, 0.04988360404968262, 105009, 5)]"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "def test_heuristics_timing(printy):\n",
        "    results = []\n",
        "    for columns in range(4, 11):  # Testing boards from 4 to 10 columns\n",
        "        game = ConnectFourHueristic(mark=1, rows=6, columns=columns)\n",
        "        start_time = time.time()\n",
        "        move, score = game.minimax_search()\n",
        "        duration = time.time() - start_time\n",
        "        results.append((columns, duration, score, move))\n",
        "        if printy == 1: print(f\"Columns: {columns}, Time Taken: {duration:.4f} seconds, Score: {score}, Move: {move}\")\n",
        "\n",
        "    return results\n",
        "\n",
        "test_heuristics_timing(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dsLGt0G49Nr"
      },
      "source": [
        "### Cutting Off Search [10 points]\n",
        "\n",
        "Modify your minimax search with alpha-beta pruning to cut off search at a specified depth and use the heuristic evaluation function. Experiment with different cutoff values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "kvmzD1sC49Nr"
      },
      "outputs": [],
      "source": [
        "# Your code/ answer goes here.\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "class ConnectFourHueristicDepth:\n",
        "\n",
        "    def __init__(self, mark, rows=6, columns=7, board=None):\n",
        "        self.rows = rows\n",
        "        self.columns = columns\n",
        "        if board is None:\n",
        "            self.board = np.zeros((rows, columns), dtype=int)\n",
        "        else:\n",
        "            self.board = np.array(board, dtype=int)\n",
        "        self.current_player = mark\n",
        "        self.last_move = []\n",
        "\n",
        "    def create_random_board(self, rows=None, columns=None):\n",
        "        # Create an empty board\n",
        "        if rows == None: rows = self.rows\n",
        "        if columns == None: columns = self.columns\n",
        "        board = np.zeros((rows, columns), dtype=int)\n",
        "        player = self.get_player()\n",
        "\n",
        "        for col in range(columns):\n",
        "            # Determine a random number of pieces in this column\n",
        "            pieces_in_col = random.randint(0, rows)\n",
        "\n",
        "            for row in range(pieces_in_col):\n",
        "                # Add a piece to the board, ensuring it's either a 1 or -1\n",
        "                board[row, col] = player\n",
        "                player = -player\n",
        "\n",
        "        # The board has been built bottom-up, but traditionally, we visualize Connect 4 boards top-down,\n",
        "        # so we need to flip it vertically.\n",
        "        self.board = np.flip(board, 0)\n",
        "\n",
        "    # will return a +1 if player 1 has played and player 2 has not, otherwise a zero if player 2 has played or no playe has\n",
        "    # assuming game has started when function is called\n",
        "    def get_player(self):\n",
        "        num_plays = np.count_nonzero(self.board)\n",
        "\n",
        "        # If the number of plays is even, it's player 1's turn (return 1). Otherwise, it's player 2's turn (return -1).\n",
        "        return 1 if num_plays % 2 == 0 else -1\n",
        "\n",
        "    def actions(self):\n",
        "        center = self.columns // 2\n",
        "        # Order actions based on their distance from the center column\n",
        "        return sorted([col for col in range(self.columns) if self.board[0, col] == 0],\n",
        "                    key=lambda x: abs(x - center))\n",
        "\n",
        "\n",
        "    def result(self, action):\n",
        "        new_state = self.board.copy()\n",
        "        for row in range(self.rows - 1, -1, -1):  # Start checking from bottom row\n",
        "            if new_state[row, action] == 0:\n",
        "                new_state[row, action] = self.current_player\n",
        "                break\n",
        "        return new_state\n",
        "\n",
        "    def undo(self):\n",
        "        if self.last_move:\n",
        "            last_col = self.last_move.pop()\n",
        "            for row in range(self.rows):\n",
        "                if self.board[row, last_col] != 0:\n",
        "                    self.board[row, last_col] = 0\n",
        "                    break\n",
        "        self.current_player *= -1  # Switch back the player\n",
        "\n",
        "    def terminal(self):\n",
        "        return self.check_board() != 2\n",
        "\n",
        "    def utility(self):\n",
        "        result = self.check_board()\n",
        "        if result == 1:\n",
        "            return 1  # Maximizer wins\n",
        "        elif result == -1:\n",
        "            return -1  # Minimizer wins\n",
        "        return 0  # Draw\n",
        "\n",
        "    def evaluate_segment(self, segment, player):\n",
        "        score = 0\n",
        "        opponent = -player\n",
        "        player_count = np.count_nonzero(segment == player)\n",
        "        opponent_count = np.count_nonzero(segment == opponent)\n",
        "        empty_count = np.count_nonzero(segment == 0)\n",
        "\n",
        "        # More nuanced scoring\n",
        "        if player_count == 4:\n",
        "            score += 10000  # Winning condition\n",
        "        elif opponent_count == 4:\n",
        "            score -= 5000   # Losing condition\n",
        "        elif player_count == 3 and empty_count == 1:\n",
        "            score += 100    # Potential to win\n",
        "        elif opponent_count == 3 and empty_count == 1:\n",
        "            score -= 50     # Need to block opponent\n",
        "        elif player_count == 2 and empty_count == 2:\n",
        "            score += 10     # Building opportunity\n",
        "        elif opponent_count == 2 and empty_count == 2:\n",
        "            score -= 5      # Opponent building opportunity\n",
        "\n",
        "        return score\n",
        "\n",
        "    def heuristic(self):\n",
        "        score = 0\n",
        "        player = self.current_player\n",
        "\n",
        "        for row in range(self.rows):\n",
        "            for col in range(self.columns - 3):\n",
        "                # Evaluate horizontal segment\n",
        "                horiz_seg = self.board[row, col:col+4]\n",
        "                score += self.evaluate_segment(horiz_seg, player)\n",
        "\n",
        "                if row < self.rows - 3:\n",
        "                    # Evaluate vertical segment\n",
        "                    vert_seg = self.board[row:row+4, col]\n",
        "                    score += self.evaluate_segment(vert_seg, player)\n",
        "\n",
        "                    # Evaluate diagonal segments\n",
        "                    diag1 = self.board[row:row+4, col:col+4].diagonal()\n",
        "                    score += self.evaluate_segment(diag1, player)\n",
        "                    diag2 = np.fliplr(self.board[row:row+4, col:col+4]).diagonal()\n",
        "                    score += self.evaluate_segment(diag2, player)\n",
        "\n",
        "        # Consider center column control as a strategy\n",
        "        center_col = self.columns // 2\n",
        "        center_control = np.count_nonzero(self.board[:, center_col] == player)\n",
        "        score += center_control * 3  # Additional points for center control\n",
        "\n",
        "        return score\n",
        "\n",
        "\n",
        "    def check_direction(self, start_row, start_col, dr, dc, player):\n",
        "        # Check if a line of four of the player's pieces exists starting from (start_row, start_col) in direction (dr, dc)\n",
        "        for i in range(4):\n",
        "            row = start_row + i * dr\n",
        "            col = start_col + i * dc\n",
        "            if not (0 <= row < self.rows and 0 <= col < self.columns):  # Check bounds\n",
        "                return False\n",
        "            if self.board[row, col] != player:\n",
        "                return False\n",
        "        return True\n",
        "\n",
        "    def check_board(self):\n",
        "        # Define the winning sequence for players\n",
        "        player_markers = [1, -1]\n",
        "\n",
        "        # Define directions to check: vertical, horizontal, diagonal down-right, diagonal up-right\n",
        "        directions = [(0, 1), (1, 0), (1, 1), (-1, 1)]\n",
        "\n",
        "        for player in player_markers:\n",
        "            for row in range(self.rows):\n",
        "                for col in range(self.columns):\n",
        "                    # Check all four directions from the current cell\n",
        "                    for dr, dc in directions:\n",
        "                        if self.check_direction(row, col, dr, dc, player):\n",
        "                            return player  # Current player wins\n",
        "\n",
        "        # Check for a full board without a winner (draw)\n",
        "        if np.all(self.board != 0):\n",
        "            return 0  # Draw\n",
        "\n",
        "        return 2  # No winner yet\n",
        "\n",
        "    def minimax_search(self, depth=7, alpha=-math.inf, beta=math.inf):\n",
        "        # Perform a Minimax search with alpha-beta pruning\n",
        "        best_score, best_move = self.max_value(depth, alpha, beta)\n",
        "        return best_move, best_score\n",
        "\n",
        "    def max_value(self, depth, alpha, beta):\n",
        "        if depth == 0 or self.terminal():\n",
        "            return self.heuristic(), None\n",
        "        max_score, best_action = -math.inf, None\n",
        "        for action in self.actions():\n",
        "            new_state = self.result(action)\n",
        "            self.board = new_state\n",
        "            self.current_player = -self.current_player\n",
        "            score, _ = self.min_value(depth - 1, alpha, beta)\n",
        "            self.board = self.board  # Reset to the original state\n",
        "            self.current_player = -self.current_player\n",
        "            if score > max_score:\n",
        "                max_score, best_action = score, action\n",
        "            alpha = max(alpha, score)\n",
        "            if alpha >= beta:\n",
        "                break\n",
        "        return max_score, best_action\n",
        "\n",
        "    def min_value(self, depth, alpha, beta):\n",
        "        if depth == 0 or self.terminal():\n",
        "            return self.heuristic(), None\n",
        "        min_score, best_action = math.inf, None\n",
        "        for action in self.actions():\n",
        "            new_state = self.result(action)\n",
        "            self.board = new_state\n",
        "            self.current_player = -self.current_player\n",
        "            score, _ = self.max_value(depth - 1, alpha, beta)\n",
        "            self.board = self.board  # Reset to the original state\n",
        "            self.current_player = -self.current_player\n",
        "            if score < min_score:\n",
        "                min_score, best_action = score, action\n",
        "            beta = min(beta, score)\n",
        "            if beta <= alpha:\n",
        "                break\n",
        "        return min_score, best_action\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2H3xgx449Ns"
      },
      "source": [
        "Experiment with the same manually created boards as above to check if the agent spots wining opportunities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "8fbuVyDh49Ns"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Board 1:\n",
            "[[ 0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0]\n",
            " [ 0  0  0  1 -1  0  0]\n",
            " [ 0  0  1 -1  1  0  0]]\n",
            "Move: 3, Score: -46\n",
            "\n",
            "Board 2:\n",
            "[[ 0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0]\n",
            " [ 0  0  0 -1  1  0  0]\n",
            " [ 0  0  0  1 -1  0  0]\n",
            " [ 0  0  0 -1  1  0  0]\n",
            " [ 0  0  1  1 -1  0  0]]\n",
            "Move: 2, Score: 5009\n",
            "\n",
            "Board 3:\n",
            "[[ 0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0]\n",
            " [ 0  0  0 -1  1  0  0]\n",
            " [ 0  0  0  1 -1  0  0]\n",
            " [ 0  0  0  1  1 -1  0]]\n",
            "Move: 3, Score: -29\n",
            "\n",
            "Board 4:\n",
            "[[ 0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0]\n",
            " [ 0  0  0  1  0  0  0]\n",
            " [ 0  0  0  1 -1  0  0]\n",
            " [ 0  0  0  1  1  1  0]]\n",
            "Move: 3, Score: -5165\n",
            "\n",
            "Board 5:\n",
            "[[ 0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0]\n",
            " [ 1  1  1 -1 -1 -1  1]]\n",
            "Move: 3, Score: 19994\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Define five predefined boards\n",
        "boards = [\n",
        "    np.array([\n",
        "        [0, 0, 0, 0, 0, 0, 0],\n",
        "        [0, 0, 0, 0, 0, 0, 0],\n",
        "        [0, 0, 0, 0, 0, 0, 0],\n",
        "        [0, 0, 0, 0, 0, 0, 0],\n",
        "        [0, 0, 0, 1, -1, 0, 0],\n",
        "        [0, 0, 1, -1, 1, 0, 0]\n",
        "    ]),\n",
        "    np.array([\n",
        "        [0, 0, 0, 0, 0, 0, 0],\n",
        "        [0, 0, 0, 0, 0, 0, 0],\n",
        "        [0, 0, 0, -1, 1, 0, 0],\n",
        "        [0, 0, 0, 1, -1, 0, 0],\n",
        "        [0, 0, 0, -1, 1, 0, 0],\n",
        "        [0, 0, 1, 1, -1, 0, 0]\n",
        "    ]),\n",
        "    np.array([\n",
        "        [0, 0, 0, 0, 0, 0, 0],\n",
        "        [0, 0, 0, 0, 0, 0, 0],\n",
        "        [0, 0, 0, 0, 0, 0, 0],\n",
        "        [0, 0, 0, -1, 1, 0, 0],\n",
        "        [0, 0, 0, 1, -1, 0, 0],\n",
        "        [0, 0, 0, 1, 1, -1, 0]\n",
        "    ]),\n",
        "    np.array([\n",
        "        [0, 0, 0, 0, 0, 0, 0],\n",
        "        [0, 0, 0, 0, 0, 0, 0],\n",
        "        [0, 0, 0, 0, 0, 0, 0],\n",
        "        [0, 0, 0, 1, 0, 0, 0],\n",
        "        [0, 0, 0, 1, -1, 0, 0],\n",
        "        [0, 0, 0, 1, 1, 1, 0]\n",
        "    ]),\n",
        "    np.array([\n",
        "        [0, 0, 0, 0, 0, 0, 0],\n",
        "        [0, 0, 0, 0, 0, 0, 0],\n",
        "        [0, 0, 0, 0, 0, 0, 0],\n",
        "        [0, 0, 0, 0, 0, 0, 0],\n",
        "        [0, 0, 0, 0, 0, 0, 0],\n",
        "        [1, 1, 1, -1, -1, -1, 1]\n",
        "    ])\n",
        "]\n",
        "\n",
        "# Test the ConnectFourMMABP agent with these boards\n",
        "for i, board in enumerate(boards):\n",
        "    game = ConnectFourHueristicDepth(mark=1, board=board)\n",
        "    print(f\"Board {i+1}:\")\n",
        "    print(game.board)\n",
        "    move, score = game.minimax_search()\n",
        "    print(f\"Move: {move}, Score: {score}\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxK95haR49Nt"
      },
      "source": [
        "How long does it take to make a move? Start with a smaller board with 4 columns and make the board larger by adding columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "OSSU4-zX49Nt"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Columns: 4, Time Taken: 0.0024 seconds, Score: 15009, Move: 1\n",
            "Columns: 5, Time Taken: 0.0031 seconds, Score: 30009, Move: 1\n",
            "Columns: 6, Time Taken: 0.0056 seconds, Score: 45009, Move: 2\n",
            "Columns: 7, Time Taken: 0.0111 seconds, Score: 60009, Move: 2\n",
            "Columns: 8, Time Taken: 0.0112 seconds, Score: 75009, Move: 3\n",
            "Columns: 9, Time Taken: 0.0164 seconds, Score: 90009, Move: 3\n",
            "Columns: 10, Time Taken: 0.0211 seconds, Score: 105009, Move: 4\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[(4, 0.0023870468139648438, 15009, 1),\n",
              " (5, 0.0030524730682373047, 30009, 1),\n",
              " (6, 0.005591392517089844, 45009, 2),\n",
              " (7, 0.01114201545715332, 60009, 2),\n",
              " (8, 0.011177301406860352, 75009, 3),\n",
              " (9, 0.01639699935913086, 90009, 3),\n",
              " (10, 0.02111649513244629, 105009, 4)]"
            ]
          },
          "execution_count": 98,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Your code/ answer goes here.\n",
        "import time\n",
        "\n",
        "def test_heuristics_depth_timing(printy):\n",
        "    results = []\n",
        "    for columns in range(4, 11):  # Testing boards from 4 to 10 columns\n",
        "        game = ConnectFourHueristicDepth(mark=1, rows=6, columns=columns)\n",
        "        start_time = time.time()\n",
        "        move, score = game.minimax_search()\n",
        "        duration = time.time() - start_time\n",
        "        results.append((columns, duration, score, move))\n",
        "        if printy == 1: print(f\"Columns: {columns}, Time Taken: {duration:.4f} seconds, Score: {score}, Move: {move}\")\n",
        "\n",
        "    return results\n",
        "\n",
        "test_heuristics_depth_timing(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLKyO9XI49Nt"
      },
      "source": [
        "### Playtime [5 points]\n",
        "\n",
        "Let two heuristic search agents (different cutoff depth, different heuristic evaluation function) compete against each other on a reasonably sized board. Since there is no randomness, you only need to let them play once."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "N88KaEC649Nu"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Game results after 1 games: {'Player 1 Wins': 1, 'Player 2 Wins': 0, 'Draws': 0}\n"
          ]
        }
      ],
      "source": [
        "# Your code/ answer goes here.\n",
        "class HeuristicMinimaxAgent:\n",
        "    def __init__(self, mark, depth=7):\n",
        "        self.mark = mark\n",
        "        self.depth = depth\n",
        "\n",
        "    def choose_action(self, game):\n",
        "        game.current_player = self.mark  # Set the current player to this agent's mark\n",
        "        best_move, _ = game.minimax_search(depth=self.depth)\n",
        "        return best_move\n",
        "\n",
        "def simulate_game(agent1, agent2, game_class, num_games=1):\n",
        "    results = {'Player 1 Wins': 0, 'Player 2 Wins': 0, 'Draws': 0}\n",
        "    for _ in range(num_games):\n",
        "        game = game_class(mark=1)  # Initialize the game with player 1 starting\n",
        "        while not game.terminal():\n",
        "            current_agent = agent1 if game.get_player() == 1 else agent2\n",
        "            action = current_agent.choose_action(game)\n",
        "            if action is not None:\n",
        "                game.board = game.result(action)  # Update the game state\n",
        "                game.current_player *= -1  # Switch player\n",
        "            else:\n",
        "                break  # No more moves available\n",
        "\n",
        "        result = game.utility()\n",
        "        if result == 1:\n",
        "            results['Player 1 Wins'] += 1\n",
        "        elif result == -1:\n",
        "            results['Player 2 Wins'] += 1\n",
        "        else:\n",
        "            results['Draws'] += 1\n",
        "\n",
        "    return results\n",
        "\n",
        "# Create two agents, possibly with different depths\n",
        "agent1 = HeuristicMinimaxAgent(mark=1, depth=7)\n",
        "agent2 = HeuristicMinimaxAgent(mark=-1, depth=10)\n",
        "\n",
        "# Run the simulation\n",
        "game_results = simulate_game(agent1, agent2, ConnectFourHueristicDepth, num_games=1)\n",
        "print(\"Game results after 1 games:\", game_results)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fZC1oKK49Nu"
      },
      "source": [
        "## Challenge task [up to +10 bonus point will be awarded separately]\n",
        "\n",
        "Find another student and let your best agent play against the other student's best player. We will set up a class tournament on Canvas. This tournament will continue after the submission deadline."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FfrcmPj49Nv"
      },
      "source": [
        "## Graduate student advanced task: Pure Monte Carlo Search and Best First Move [10 point]\n",
        "\n",
        "__Undergraduate students:__ This is a bonus task you can attempt if you like [+5 bonus point].\n",
        "\n",
        "### Pure Monte Carlo Search\n",
        "\n",
        "Implement Pure Monte Carlo Search and investigate how this search performs on the test boards that you have used above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "suqBzw6a49Nv"
      },
      "outputs": [],
      "source": [
        "# Your code/ answer goes here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXuL1zHx49Nv"
      },
      "source": [
        "### Best First Move\n",
        "\n",
        "Use Oure Monte Carlo Search to determine what the best first move is? Describe under what assumptions this is the \"best\" first move.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wJo6qgV849Nw"
      },
      "outputs": [],
      "source": [
        "# Your code/ answer goes here."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
